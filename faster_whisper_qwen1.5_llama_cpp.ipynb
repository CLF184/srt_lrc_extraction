{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from llama_cpp import Llama\n",
    "from faster_whisper import WhisperModel # type: ignore\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size=\"large-v3\"\n",
    "model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n",
    "\"\"\"\n",
    "Size\tParameters\tEnglish-only model\tMultilingual model\tRequired VRAM\tRelative speed\n",
    "tiny\t39 M\t    tiny.en\t            tiny\t            ~1 GB\t        ~32x\n",
    "base\t74 M\t    base.en\t            base\t            ~1 GB\t        ~16x\n",
    "small\t244 M\t    small.en\t        small\t            ~2 GB\t        ~6x\n",
    "medium\t769 M\t    medium.en\t        medium\t            ~5 GB\t        ~2x\n",
    "large\t1550 M\t    N/A\t                large\t            ~10 GB\t        1x\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=\"./\"\n",
    "file=\"xxx.mp4\"\n",
    "format=\"lrc\" # lrc, srt\n",
    "file_name=os.path.splitext(file)[0]\n",
    "context_window=4096\n",
    "vad_filter=False\n",
    "language=None\n",
    "replace_file=True\n",
    "memory=True\n",
    "model_path=\"E:\\Download\\qwen1_5-14b-chat-q2_k.gguf\" # 通义千问1.5-14B-Chat-GGUF\n",
    "audio=dir+file\n",
    "llm=None\n",
    "history_golbal=[{\"role\": \"system\", \"content\": \"你是一个翻译专家。现在开始，你将所有的句子都把它翻译为的中文。注意：不要添加原文没有的词语,保证翻译的准确性,不需要去解释句子。\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transcribe(audio, language=language,vad_filter=vad_filter,vad_parameters=dict(min_silence_duration_ms=500))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_lrc(file,result):\n",
    "    with open(file,'w',encoding='utf-8') as lrcfile:\n",
    "        for result in result:\n",
    "            start=convert_time(result.start)[0]\n",
    "            end=convert_time(result.end)[0]\n",
    "            lrcfile.write(f\"[{start}]{result.text}\\n[{end}]\\n\")\n",
    "            print(f\"[{start}]{result.text}\")\n",
    "\n",
    "def write_srt(file,result):\n",
    "    with open(file,'w',encoding='utf-8') as srtfile:\n",
    "        for i,result in enumerate(result):\n",
    "            start=convert_time(result.start)[1]\n",
    "            end=convert_time(result.end)[1]\n",
    "            srtfile.write(f\"{i}\\n{start} --> {end}\\n{result.text}\\n\\n\")\n",
    "            print(f\"[{start}]{result.text}\")\n",
    "\n",
    "def write(file,result,format):\n",
    "    if format==\"lrc\":\n",
    "        write_lrc(file+\".lrc\",result)\n",
    "    elif format==\"srt\":\n",
    "        write_srt(file+\".srt\",result)\n",
    "\n",
    "def convert_time(seconds):\n",
    "    # 将秒数转换为毫秒\n",
    "    milliseconds = int(seconds * 1000)\n",
    "    hours = milliseconds // 3600000\n",
    "    minutes = milliseconds // 60000\n",
    "    seconds = (milliseconds % 60000) // 1000\n",
    "    millis_1 = milliseconds % 100\n",
    "    millis_2 = milliseconds % 1000\n",
    "    # 格式化输出\n",
    "    return f\"{minutes:02d}:{seconds:02d}.{millis_1:02d}\",f\"{hours:02d}:{minutes:02d}:{seconds:02d},{millis_2:03d}\"\n",
    "\n",
    "write(f\"{dir}{file_name}\",result,format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    global llm\n",
    "    llm = Llama(\n",
    "    model_path,\n",
    "    n_gpu_layers=-1, # Uncomment to use GPU acceleration\n",
    "    seed=1234, # Uncomment to set a specific seed\n",
    "    n_ctx=context_window, # Uncomment to increase the context window\n",
    ")\n",
    "\n",
    "load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text):\n",
    "    global llm,history_golbal\n",
    "    history=history_golbal.copy()\n",
    "    history.append({\"role\": \"user\", \"content\": text})\n",
    "    flag=True\n",
    "    while flag:\n",
    "        try:\n",
    "            out=llm.create_chat_completion(history)\n",
    "        except Exception as e:\n",
    "            if \"exceed context window \" in str(e):\n",
    "                del history[1:-1]\n",
    "                continue\n",
    "        flag=False\n",
    "    result=out.get(\"choices\")[0].get(\"message\").get(\"content\")\n",
    "    history.append({\"role\": \"assistant\", \"content\": result})\n",
    "    if memory:\n",
    "        history_golbal=history.copy()\n",
    "    else:\n",
    "        del history\n",
    "    return result\n",
    "\n",
    "def lrc_tran(lrc_file_path):\n",
    "    new_lrc_file_path = lrc_file_path.replace('.lrc', ' - 翻译.lrc')\n",
    "    with open(lrc_file_path, 'r', encoding='utf-8-sig') as lrc_file,\\\n",
    "        open(new_lrc_file_path, 'w', encoding='utf-8-sig') as new_lrc_file:\n",
    "        lines = lrc_file.readlines()\n",
    "        for i in range(0, len(lines), 2):\n",
    "            time_start=re.match(r'\\[(\\d{2}:\\d{2}\\.\\d{2})\\]',lines[i])\n",
    "            time_end=re.match(r'\\[(\\d{2}:\\d{2}\\.\\d{2})\\]',lines[i+1])\n",
    "            text = lines[i][time_start.end():].strip()\n",
    "            time_start = time_start.group(1)\n",
    "            time_end = time_end.group(1)\n",
    "            trans=translate(text)\n",
    "            new_lrc_file.write(f\"[{time_start}]{text}\\n[{time_start}]{trans}\\n\")\n",
    "            print(f\"[{time_start}]{trans}\\n\")\n",
    "\n",
    "def srt_tran(srt_file_path):\n",
    "    new_srt_file_path = srt_file_path.replace('.srt', ' - 翻译.srt')\n",
    "    with open(srt_file_path, 'r', encoding='utf-8-sig') as srt_file,\\\n",
    "        open(new_srt_file_path, 'w', encoding='utf-8-sig') as new_srt_file:\n",
    "        lines = srt_file.readlines()\n",
    "        for i in range(0, len(lines), 4):\n",
    "            trans=translate(lines[i+2].strip())\n",
    "            new_srt_file.write(f\"{lines[i]}{lines[i+1]}{trans}{lines[i+3]}\\n\")\n",
    "            print(f\"{lines[i+1].strip().split(' --> ')[0]}  {trans}\")\n",
    "            \n",
    "def tran(file_name,format):\n",
    "    if format==\"lrc\":\n",
    "        lrc_tran(file_name+\".lrc\")\n",
    "    elif format==\"srt\":\n",
    "        srt_tran(file_name+\".srt\")\n",
    "\n",
    "tran(f\"{dir}{file_name}\",format)\n",
    "\n",
    "if(replace_file):\n",
    "    os.remove(f\"{dir}{file_name}.{format}\")\n",
    "    os.rename(f\"{dir}{file_name} - 翻译.{format}\",f\"{dir}{file_name}.{format}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
